# ğŸ§  VisionTouch OS â€” Gesture-Controlled Humanâ€“Computer Interface

VisionTouch OS is a **real-time computer vision system** that converts **hand gestures into system-level controls** using a webcam.

It allows users to control a computer **without touching a mouse or keyboard**, demonstrating **Computer Vision**, **Humanâ€“Computer Interaction (HCI)**, and **OS-level automation**.

---

## ğŸ¯ What This Project Does

Using live webcam input, VisionTouch OS enables:

- ğŸ–±ï¸ Mouse movement  
- ğŸ‘† Left click  
- ğŸ‘‰ Right click  
- ğŸ–ï¸ Scroll  
- ğŸ”Š System volume control (Windows)

All interactions happen **in real time**, using only **hand gestures**.

---

## ğŸ¥ Demo Video

The demo video is included directly in the repository

---

## ğŸ§  High-Level Architecture

```
Webcam
  â†“
OpenCV (Frame Capture)
  â†“
MediaPipe Hands (Landmarks + Handedness)
  â†“
Custom Logic Layer
  â”œâ”€ Physical Right Hand â†’ Mouse Control
  â””â”€ Physical Left Hand  â†’ Volume Control
  â†“
OS Interaction Layer
  â”œâ”€ autopy     (Mouse movement & clicks)
  â”œâ”€ pyautogui  (Scrolling)
  â””â”€ pycaw      (System volume)
```

**Hand separation** is the key design choice that keeps the system stable and usable.

---

## ğŸ“¦ Libraries Used & Why

### ğŸ” Core Computer Vision
- **OpenCV (`cv2`)** â€” webcam input, frame processing, UI overlays
- **MediaPipe Hands** â€” 21 landmarks, handedness detection

### ğŸ§® Math & Utilities
- **NumPy** â€” interpolation, smoothing
- **math.hypot** â€” distance calculation
- **time** â€” FPS calculation

### ğŸ–¥ï¸ OS-Level Control
- **autopy** â€” mouse movement & clicks
- **pyautogui** â€” scrolling
- **pycaw** â€” system volume control (Windows)

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/shaurya0702-droid/VisionTouch.git
cd VisionTouch
```

---

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
```

Activate it:

**Windows**
```bash
venv\Scripts\activate
```

**Linux / macOS**
```bash
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install Dependencies

`requirements.txt`

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run VisionTouch OS

Run the main file from terminal:

```bash
python visiontouch.py
```

Press **`q`** to safely exit.

---

## ğŸ“· Camera & Screen Configuration

```python
wCam, hCam = 640, 480
cap = cv2.VideoCapture(0)
cap.set(3, wCam)
cap.set(4, hCam)

wScr, hScr = autopy.screen.size()
```

Fixed resolution ensures:
- Predictable hand mapping
- Reduced jitter
- Stable gestures

---

## ğŸ›¡ï¸ Gesture Safety & Stability Controls

```python
frameR = 100
PINCH_DISTANCE = 20
RELEASE_DISTANCE = 35
smoothening = 6
```

Why this matters:
- Prevents accidental clicks
- Smooth cursor motion
- Production-level UX safety

---

## ğŸ§© Hand Detection Engine

### `handDetector` Class

```python
self.handType = handInfo.classification[0].label
```

âš  MediaPipe feed is **not mirrored**:
- `"Right"` â†’ Physical left hand  
- `"Left"` â†’ Physical right hand  

Handled correctly in logic.

---

## ğŸ”Š Volume Control (Physical LEFT Hand)

```python
pinchDist = hypot(middle - thumb)

if pinchDist < 25:
    volumeActive = True
elif pinchDist > 40:
    volumeActive = False
```

Gesture gating prevents accidental volume change.

```python
length = hypot(index - thumb)
volPer = interp(length, [10, 150], [0, 1])
volume.SetMasterVolumeLevelScalar(volPer, None)
```

Controls **real system volume**.

---

## ğŸ–±ï¸ Mouse Control (Physical RIGHT Hand)

```python
x3 = interp(x1, camera_range, screen_range)
clocX = plocX + (x3 - plocX) / smoothening
```

Low-pass filtering ensures smooth movement.

---

## ğŸ‘† Click Gestures

- **Left Click** â†’ Index + Thumb pinch  
- **Right Click** â†’ Middle + Thumb pinch  
- Both are **debounced** to prevent spam clicks

---

## ğŸ–ï¸ Scroll Mode (Open Palm)

```python
tip_y < knuckle_y
scrollDelta = prevScrollY - index_tip
pyautogui.scroll(-scrollDelta)
```

Continuous gesture-based scrolling.

---

## ğŸ” Mode Priority

1. Volume  
2. Scroll  
3. Click  
4. Cursor movement  

Prevents gesture collision.

---

## ğŸ“Š Performance Monitoring

```python
fps = 1 / (cTime - pTimeFPS)
```

Ensures real-time inference.

---

## âŒ Exit Handling

```python
if cv2.waitKey(1) & 0xFF == ord('q'):
```

Clean shutdown:
- Camera released
- Windows destroyed
- No memory leak

---

## ğŸ§ª Key Concepts Demonstrated

- Computer Vision  
- Real-time systems  
- Gesture recognition  
- Humanâ€“Computer Interaction  
- OS-level automation  
- UX safety mechanisms  

---

## â­ Demonstrates: 

- âœ… Advanced CV
- âœ… Real-time interaction
- âœ… OS-level control
- âœ… Clean modular design


